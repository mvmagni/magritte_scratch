{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa185193-b0eb-43ed-8a58-641abae6c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afaa92a7-add6-40c6-8b3a-2e24b12b430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Index_Name         Notes\n",
      "0    index 1   test text 1\n",
      "1    index 2   test text 2\n",
      "2    index 3   test text 3\n",
      "3    index 4   test text 4\n",
      "4    index 5   test text 5\n",
      "5    index 6   test text 6\n",
      "6    index 7   test text 7\n",
      "7    index 8   test text 8\n",
      "8    index 9   test text 9\n",
      "9   index 10  test text 10\n"
     ]
    }
   ],
   "source": [
    "# Create test dataframe\n",
    "lst = [['index 1',  'test text 1'],\n",
    "       ['index 2',  'test text 2'],\n",
    "       ['index 3',  'test text 3'],\n",
    "       ['index 4',  'test text 4'],\n",
    "       ['index 5',  'test text 5'],\n",
    "       ['index 6',  'test text 6'],\n",
    "       ['index 7',  'test text 7'],\n",
    "       ['index 8',  'test text 8'],\n",
    "       ['index 9',  'test text 9'],\n",
    "       ['index 10', 'test text 10']\n",
    "      ]\n",
    "\n",
    "df = pd.DataFrame(lst, columns = ['Index_Name', 'Notes'])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f882235-517f-4352-9b69-13ee8576d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_text(dataFrame,\n",
    "                data_column,\n",
    "                iteration_text,\n",
    "                lower=None,\n",
    "                upper=None):\n",
    "  \n",
    "  print(f'Processing {iteration_text}')\n",
    "   \n",
    "  column_index = dataFrame.columns.get_loc(data_column)\n",
    "   \n",
    "  dataFrame.iloc[:,column_index] = dataFrame.iloc[:,column_index].apply(lambda x: x + ' ' + iteration_text)\n",
    "  #return f'Finish: {iteration_text}'\n",
    "  return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa6b427-7607-4e87-9fa5-f1bda16b0e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 456\n",
      "  Index_Name             Notes\n",
      "0    index 1   test text 1 456\n",
      "1    index 2   test text 2 456\n",
      "2    index 3   test text 3 456\n",
      "3    index 4   test text 4 456\n",
      "4    index 5   test text 5 456\n",
      "5    index 6   test text 6 456\n",
      "6    index 7   test text 7 456\n",
      "7    index 8   test text 8 456\n",
      "8    index 9   test text 9 456\n",
      "9   index 10  test text 10 456\n"
     ]
    }
   ],
   "source": [
    "append_text(dataFrame=df,\n",
    "            data_column='Notes',\n",
    "            iteration_text='456')\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31da06f-09e7-4295-84e0-71b43c41a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing single1\n",
      "  Index_Name             Notes\n",
      "0    index 1   test text 1 456\n",
      "1    index 2   test text 2 456\n",
      "2    index 3   test text 3 456\n",
      "3    index 4   test text 4 456\n",
      "4    index 5   test text 5 456\n",
      "5    index 6   test text 6 456\n",
      "6    index 7   test text 7 456\n",
      "7    index 8   test text 8 456\n",
      "8    index 9   test text 9 456\n",
      "9   index 10  test text 10 456\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "starmap_input = [[df, 'Notes', 'single1']\n",
    "                ]\n",
    "\n",
    "with Pool(processes=1) as pool:  \n",
    "    results = pool.starmap(append_text, starmap_input)\n",
    "\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fa69b7-cb9a-4b18-bd9b-b14df87e62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  Index_Name            Notes\n",
      "0    index 1  test text 1 456\n",
      "1    index 2  test text 2 456\n",
      "2    index 3  test text 3 456, 'Notes', 'counter_1'], [  Index_Name            Notes\n",
      "3    index 4  test text 4 456\n",
      "4    index 5  test text 5 456\n",
      "5    index 6  test text 6 456, 'Notes', 'counter_2'], [  Index_Name            Notes\n",
      "6    index 7  test text 7 456\n",
      "7    index 8  test text 8 456, 'Notes', 'counter_3'], [  Index_Name             Notes\n",
      "8    index 9   test text 9 456\n",
      "9   index 10  test text 10 456, 'Notes', 'counter_4']]\n"
     ]
    }
   ],
   "source": [
    "# Test creation of df breakdown and building input to functions\n",
    "\n",
    "func_input = []\n",
    "\n",
    "df_split = np.array_split(df, 4)\n",
    "for count, df_part in enumerate(df_split, start=1):\n",
    "    func_input.append([df_part, 'Notes', f'counter_{count}'])\n",
    "\n",
    "#print (func_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61def84b-8c82-4058-9526-db72fee5a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(func_input, n_cores=4):\n",
    "    pool = Pool(n_cores)\n",
    "    final_df = pd.concat(pool.starmap(append_text, func_input))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4ff1e4-f3cc-4a52-bd5f-85eb375b157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing counter_2Processing counter_3Processing counter_1Processing counter_4\n",
      "\n",
      "\n",
      "\n",
      "  Index_Name                       Notes\n",
      "0    index 1   test text 1 456 counter_1\n",
      "1    index 2   test text 2 456 counter_1\n",
      "2    index 3   test text 3 456 counter_1\n",
      "3    index 4   test text 4 456 counter_2\n",
      "4    index 5   test text 5 456 counter_2\n",
      "5    index 6   test text 6 456 counter_2\n",
      "6    index 7   test text 7 456 counter_3\n",
      "7    index 8   test text 8 456 counter_3\n",
      "8    index 9   test text 9 456 counter_4\n",
      "9   index 10  test text 10 456 counter_4\n"
     ]
    }
   ],
   "source": [
    "newDF = parallelize_dataframe(func_input, n_cores=4)\n",
    "print(newDF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88523e2-8a94-423e-8d3a-8c3868b4e671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7173d4e9-9e11-460f-9041-724ddc348579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fb72fc7-fbdd-4980-9b77-ba1b7a3295cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Nick likes to play football, however he is not too fond of tennis. \n",
      "Cleaned:  Nick likes play football , fond tennis .\n"
     ]
    }
   ],
   "source": [
    "text = \"Nick likes to play football, however he is not too fond of tennis. \"\n",
    "\n",
    "text_tokens = word_tokenize(text)\n",
    "\n",
    "cleaned_text = ' '.join([word for word in text_tokens if not word in stopwords.words()])\n",
    "print(f'Original: {text}')\n",
    "print(f'Cleaned:  {cleaned_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d5725-4f24-46bf-9980-d3cafc098dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc9278-8d95-409f-888f-6e9376c9fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1451b121-d6e2-44bc-8cb8-42b1219e66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:           b big dog A a c D b123 b456\n",
      "All singles removed:       b big dog a D b123 b456\n",
      "Remove singles from start: b big dog A a c D b123 b456\n",
      "No prefixed b:             big dog A a c D b123 b456\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "test_string = 'b big dog A a c D b123 b456'\n",
    "print(f'Original string:           {test_string}')\n",
    "\n",
    "# remove all single characters\n",
    "no_single = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', test_string)\n",
    "print(f'All singles removed:       {no_single}')\n",
    "\n",
    "# Remove single characters from the start\n",
    "no_single2 = re.sub(r'\\^[a-zA-Z]\\s+', ' ', test_string) \n",
    "print(f'Remove singles from start: {no_single2}')\n",
    "\n",
    "# Removing prefixed 'b'\n",
    "no_prefixed_b = re.sub(r'^b\\s+', '', test_string)\n",
    "print(f'No prefixed b:             {no_prefixed_b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magritte",
   "language": "python",
   "name": "magritte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
